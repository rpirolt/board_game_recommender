{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciPy: 1.11.3\n",
      "implicit: 0.7.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy, implicit\n",
    "print(\"SciPy:\", scipy.__version__)\n",
    "print(\"implicit:\", implicit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BGGId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213788</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Tonydorrf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213788</td>\n",
       "      <td>8.0</td>\n",
       "      <td>tachyon14k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>213788</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Ungotter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213788</td>\n",
       "      <td>8.0</td>\n",
       "      <td>brainlocki3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213788</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PPMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BGGId  Rating     Username\n",
       "0  213788     8.0    Tonydorrf\n",
       "1  213788     8.0   tachyon14k\n",
       "2  213788     8.0     Ungotter\n",
       "3  213788     8.0  brainlocki3\n",
       "4  213788     8.0         PPMP"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr = pd.read_csv('data/user_ratings.csv')\n",
    "usr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_users = usr.groupby('Username').size()\n",
    "ratings_per_movies = usr.groupby('BGGId').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr['MappedRating'] = np.where(usr['Rating'] <= 4, -1,\n",
    "                       np.where(usr['Rating'] <= 7, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ratings_per_users[ratings_per_users >= 5].index\n",
    "usr = usr[usr['Username'].isin(keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "usr.groupby('Username')['MappedRating'].mean().hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18696365,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_map = {u: i for i, u in enumerate(usr['Username'].unique())}\n",
    "game_map = {g: j for j, g in enumerate(usr['BGGId'].unique())}\n",
    "\n",
    "rows = usr['Username'].map(user_map)\n",
    "cols = usr['BGGId'].map(game_map)\n",
    "\n",
    "rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "def create_A_matrix(users, items, ratings):\n",
    "\n",
    "    unique_users = np.sort(users.unique())\n",
    "    unique_items = np.sort(items.unique())\n",
    "    user_map = {user: i for i, user in enumerate(unique_users)}\n",
    "    item_map = {item: i for i, item in enumerate(unique_items)}\n",
    "    rows = users.map(user_map)\n",
    "    cols = items.map(item_map)\n",
    "\n",
    "    #mask = ratings.notna()\n",
    "    A = coo_matrix((ratings, (rows,cols)), shape=(len(user_map), len(item_map)))\n",
    "\n",
    "    return A, user_map, item_map\n",
    "\n",
    "\n",
    "A, user_map, item_map = create_A_matrix(usr['Username'], usr['BGGId'], usr['Rating'])\n",
    "rows, cols, data = A.row, A.col, A.data\n",
    "indices = np.arange(len(data))\n",
    "train, test = train_test_split(indices, test_size=0.05, random_state=42)\n",
    "\n",
    "train_rows, train_cols, train_data = rows[train], cols[train], data[train]\n",
    "#val_rows, val_cols, val_data = rows[test_index], cols[test_index], data[test_index]\n",
    "\n",
    "A_train = coo_matrix((train_data, (train_rows, train_cols)), shape=A.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als(R, k=2, W= None, lambda_=0.1, n_iters=10 ):\n",
    "    m, n = R.shape\n",
    "\n",
    "    #Global mean\n",
    "    mu = R.data.mean()\n",
    "    \n",
    "    # Initialize parameters\n",
    "    U = np.random.normal(scale=1./k, size=(m, k))\n",
    "    V = np.random.normal(scale=1./k, size=(n, k))\n",
    "    b_user = np.zeros(m)\n",
    "    b_item = np.zeros(n)\n",
    "\n",
    "    #create two versions for row and column operations\n",
    "    R_csr = R.tocsr()\n",
    "    R_csc = R.tocsc()\n",
    "\n",
    "\n",
    "    if W is None:\n",
    "        W = csr_matrix(R_csr.copy())\n",
    "        W.data[:] = 1.0\n",
    "    W_csr = W.tocsr()\n",
    "    W_csc = W.tocsc()\n",
    "\n",
    "    nonzero_users = np.unique(R_csr.nonzero()[0])\n",
    "    nonzero_items = np.unique(R_csc.nonzero()[1])\n",
    "    for _ in range(n_iters):\n",
    "        #print(f'Iteration {_+1}/{n_iters}')\n",
    "        # Update user features\n",
    "        for i in nonzero_users:\n",
    "            start, end = R_csr.indptr[i], R_csr.indptr[i+1]\n",
    "            idx  = R_csr.indices[start:end]\n",
    "            r_i = R_csr.data[start:end] \n",
    "            w_i = W_csr.data[start:end]\n",
    "            if len(idx) > 0:\n",
    "                V_i = V[idx, :]\n",
    "                W_i = np.diag(w_i)\n",
    "                r_i_centered = r_i - mu - b_user[i] - b_item[idx]\n",
    "                A = V_i.T @ W_i @ V_i + lambda_ * np.eye(k)\n",
    "                b = V_i.T @ (W_i @ r_i_centered)\n",
    "                U[i] = np.linalg.solve(A,b)\n",
    "\n",
    "                #update user bias\n",
    "                pred = V_i @ U[i]\n",
    "                b_user[i] = np.average(r_i - pred - mu - b_item[idx], weights = w_i)\n",
    "\n",
    "        # Update item features\n",
    "        for j in nonzero_items:\n",
    "            start, end = R_csc.indptr[j], R_csc.indptr[j+1]\n",
    "            idx  = R_csc.indices[start:end]            \n",
    "            r_j = R_csc.data[start:end]\n",
    "            w_j = W_csc.data[start:end]\n",
    "            if len(idx) > 0:\n",
    "                U_j = U[idx,:]\n",
    "                W_j = np.diag(w_j)\n",
    "                r_j_centered = r_j - mu - b_user[idx] - b_item[j]\n",
    "                A = U_j.T @  W_j @ U_j + lambda_ * np.eye(k)\n",
    "                b = U_j.T @ (W_j @ r_j_centered)\n",
    "                V[j] = np.linalg.solve(A,b)\n",
    "\n",
    "                #udate item bias    \n",
    "                pred = U_j @ V[j]\n",
    "                b_item[j] = np.average(r_j - pred - mu - b_user[idx], weights = w_j)\n",
    "    return U, V, b_user, b_item, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from implicit.als import AlternatingLeastSquares \n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def recall_at_k(U, V, A_train, A_val, k=10, batch_size=512, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute Recall@K for validation set A_val given factor matrices U, V,\n",
    "    and training matrix A_train (for masking), using batched scoring.\n",
    "    \"\"\"\n",
    "    A_train_csr = A_train.tocsr()\n",
    "    A_val_csr = A_val.tocsr()\n",
    "    n_users = A_val.shape[0]\n",
    "    recalls = []\n",
    "\n",
    "    for start in range(0, n_users, batch_size):\n",
    "        end = min(start + batch_size, n_users)\n",
    "        if verbose and start % (batch_size * 10) == 0:\n",
    "            print(f\"Processing users {start}-{end} / {n_users}\")\n",
    "\n",
    "        # batch of users\n",
    "        U_batch = U[start:end]                      # (batch_size, k)\n",
    "        scores_batch = U_batch @ V.T                # (batch_size, n_items)\n",
    "\n",
    "        # mask training items for each user\n",
    "        for i, u in enumerate(range(start, end)):\n",
    "            train_items = A_train_csr[u].indices\n",
    "            if len(train_items) > 0:\n",
    "                scores_batch[i, train_items] = -np.inf\n",
    "\n",
    "        # compute recall for each user in the batch\n",
    "        for i, u in enumerate(range(start, end)):\n",
    "            val_items = A_val_csr[u].indices\n",
    "            if len(val_items) == 0:\n",
    "                continue\n",
    "            topk = np.argpartition(scores_batch[i], -k)[-k:]\n",
    "            recall = len(np.intersect1d(val_items, topk)) / len(val_items)\n",
    "            recalls.append(recall)\n",
    "\n",
    "    return np.mean(recalls) if recalls else np.nan\n",
    "\n",
    "\n",
    "def recall_at_k_implicit(U, V, P_train, P_val, k=10, batch_size=512, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute Recall@K for implicit ALS factors, using batched scoring.\n",
    "    \"\"\"\n",
    "    csr_train, csr_val = P_train.tocsr(), P_val.tocsr()\n",
    "    n_users = U.shape[0]\n",
    "    recalls = []\n",
    "\n",
    "    for start in range(0, n_users, batch_size):\n",
    "        end = min(start + batch_size, n_users)\n",
    "        if verbose and start % (batch_size * 10) == 0:\n",
    "            print(f\"Processing users {start}-{end} / {n_users}\")\n",
    "\n",
    "        # batch scoring\n",
    "        U_batch = U[start:end]\n",
    "        scores_batch = U_batch @ V.T\n",
    "\n",
    "        # mask known positives\n",
    "        for i, u in enumerate(range(start, end)):\n",
    "            train_items = csr_train[u].indices\n",
    "            if len(train_items) > 0:\n",
    "                scores_batch[i, train_items] = -np.inf\n",
    "\n",
    "        # compute per-user recall\n",
    "        for i, u in enumerate(range(start, end)):\n",
    "            val_items = csr_val[u].indices\n",
    "            if len(val_items) == 0:\n",
    "                continue\n",
    "            topk = np.argpartition(scores_batch[i], -k)[-k:]\n",
    "            recall = len(np.intersect1d(val_items, topk)) / len(val_items)\n",
    "            recalls.append(recall)\n",
    "\n",
    "    return np.mean(recalls) if recalls else np.nan\n",
    "\n",
    "def precision_at_k(U, V,A_val, k=10, verbose=False):\n",
    "    precisions = []\n",
    "\n",
    "    VT = V.T\n",
    "    val_items = np.unique(A_val.col)\n",
    "\n",
    "    for u in range(U.shape[0]):\n",
    "        if u % 1000 == 0 and verbose:\n",
    "            print(f'Processing user {u}/{U.shape[0]}')\n",
    "        row = A_val.getrow(u).tocoo()\n",
    "        if row.nnz < 2: # skip users with less than 2 ratings, 1 rating is useless for precision\n",
    "            continue\n",
    "        y_true = row.col[row.data > 0] # liked items\n",
    "        if len(y_true) == 0:\n",
    "            continue\n",
    "        y_scores = U[u, :] @ VT[:,val_items]\n",
    "        topkidx = np.argpartition(-y_scores, k)[:k] #efficient lookup of top k indices\n",
    "        y_pred = val_items[topkidx[np.argsort(-y_scores[topkidx])]]  # top-k items\n",
    "\n",
    "        hits = np.intersect1d(y_true, y_pred) # how many of the true liked items are in the top-k predictions\n",
    "        precision = len(hits) / k # fraction of hits that were in the top 10 predictions\n",
    "        precisions.append(precision)\n",
    "        \n",
    "    return -np.mean(precisions) if precisions else np.nan\n",
    "    \n",
    "\n",
    "def cv_als(A, k=5,W=None, als_params = {'k':20, 'lambda':0.1, 'n_iters':10, 'alpha':15} ):\n",
    "\n",
    "    rmses = []\n",
    "    recalls = []\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    rows, cols, data = A.row, A.col, A.data\n",
    "    #indices = np.arange(len(data))\n",
    "    indices = np.arange(len(data))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "        train_rows, train_cols, train_data = rows[train_idx], cols[train_idx], data[train_idx]\n",
    "        val_rows, val_cols, val_data = rows[val_idx], cols[val_idx], data[val_idx]\n",
    "\n",
    "        A_fold_train = coo_matrix((train_data, (train_rows, train_cols)), shape=A.shape)\n",
    "        A_fold_val = coo_matrix((val_data, (val_rows, val_cols)), shape=A.shape)\n",
    "        \n",
    "        # Train your model on A_train here\n",
    "         # train implicit ALS\n",
    "        model = AlternatingLeastSquares(\n",
    "            factors=als_params['k'],\n",
    "            regularization=als_params['lambda'],\n",
    "            iterations=als_params['n_iters'],\n",
    "            num_threads=8\n",
    "        )\n",
    "        model.fit(A_fold_train)\n",
    "\n",
    "        U, V = model.user_factors, model.item_factors\n",
    "\n",
    "\n",
    "\n",
    "        # Evaluate your model on A_test here\n",
    "        #A_pred = U @ V.T\n",
    "        # Compute RMSE on the test set\n",
    "        #print(f\"Fold {fold+1}\")\n",
    "        #print(U.shape, V.shape)\n",
    "        #test values\n",
    "        y_test = A_fold_val.data\n",
    "\n",
    "        #get predictions from the predicted matrix\n",
    "        latent_pred = np.einsum('ij,ij->i', U[A_fold_val.row], V[A_fold_val.col])\n",
    "\n",
    "        b_user = np.zeros(A.shape[0])\n",
    "        b_item = np.zeros(A.shape[1])\n",
    "        mu = A_fold_train.data.mean()\n",
    "        \n",
    "\n",
    "        #add biases and global mean\n",
    "        y_pred = mu + b_user[A_fold_val.row] + b_item[A_fold_val.col] + latent_pred\n",
    "        r_at_k = recall_at_k(U, V,A_fold_train, A_fold_val, k=10)\n",
    "        rmse_ = rmse(y_test, y_pred)\n",
    "        rmses.append(rmse_)\n",
    "        recalls.append(r_at_k)\n",
    "\n",
    "    return np.mean(rmses), np.mean(recalls)\n",
    "\n",
    "\n",
    "def cv_als_implicit(A, n_splits=5, als_params={'k':20, 'lambda':0.1, 'n_iters':10, 'alpha':15}):\n",
    "    \"\"\"\n",
    "    Cross-validation for implicit ALS using user-level splits.\n",
    "    Returns mean Recall@10 across folds.\n",
    "    \"\"\"\n",
    "    recalls = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    rows, cols, data = A.row, A.col, A.data\n",
    "    users = np.arange(A.shape[0])\n",
    "\n",
    "    for fold, (train_users, val_users) in enumerate(kf.split(users)):\n",
    "        print(f\"Fold {fold+1}/{n_splits}\")\n",
    "\n",
    "        # mask by users\n",
    "        train_mask = np.isin(rows, train_users)\n",
    "        val_mask   = np.isin(rows, val_users)\n",
    "\n",
    "        train_rows, train_cols, train_data = rows[train_mask], cols[train_mask], data[train_mask]\n",
    "        val_rows, val_cols, val_data       = rows[val_mask],   cols[val_mask],   data[val_mask]\n",
    "\n",
    "        A_train = coo_matrix((train_data, (train_rows, train_cols)), shape=A.shape)\n",
    "        A_val   = coo_matrix((val_data,   (val_rows,   val_cols)),   shape=A.shape)\n",
    "\n",
    "        # confidence matrix: C = 1 + alpha * R\n",
    "        C = (A_train * als_params['alpha']).astype(np.float32).tocsr()\n",
    "        C.data = 1 + C.data\n",
    "\n",
    "        # train implicit ALS\n",
    "        model = AlternatingLeastSquares(\n",
    "            factors=als_params['k'],\n",
    "            regularization=als_params['lambda'],\n",
    "            iterations=als_params['n_iters'],\n",
    "            num_threads=8\n",
    "        )\n",
    "        model.fit(C)\n",
    "\n",
    "        # evaluate Recall@10\n",
    "        U, V = model.user_factors, model.item_factors\n",
    "        r_at_k = recall_at_k_implicit(U, V, A_train, A_val, k=10, batch_size=1024)\n",
    "        print(f\"Recall@10 = {r_at_k:.4f}\")\n",
    "        recalls.append(r_at_k)\n",
    "\n",
    "    return np.nanmean(recalls)\n",
    "\n",
    "\n",
    "def make_holdout_split(P, val_franction = 0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    csr = P.tocsr()\n",
    "    rows_t, cols_t, data_t = [], [], []\n",
    "    rows_v, cols_v, data_v = [], [], []\n",
    "\n",
    "    for u in range(P.shape[0]):\n",
    "        items = csr[u].indices\n",
    "        n_items = len(items)\n",
    "        if n_items == 0:\n",
    "            continue    \n",
    "\n",
    "        n_val = max(1, int(n_items * val_franction))\n",
    "        val_indices = np.random.choice(items, size=n_val, replace=False)\n",
    "        train_indices = np.setdiff1d(items, val_indices)\n",
    "\n",
    "        vals = csr[u].data\n",
    "        train_mask = np.isin(items, train_indices)\n",
    "        val_mask = np.isin(items, val_indices)\n",
    "\n",
    "        rows_t += [u] * np.sum(train_mask)\n",
    "        cols_t += items[train_mask].tolist()\n",
    "        data_t += vals[train_mask].tolist()\n",
    "        rows_v += [u] * np.sum(val_mask)\n",
    "        cols_v += items[val_mask].tolist()\n",
    "        data_v += vals[val_mask].tolist()\n",
    "\n",
    "    P_train = coo_matrix((data_t, (rows_t, cols_t)), shape=P.shape).tocsr()\n",
    "    P_val = coo_matrix((data_v, (rows_v, cols_v)), shape=P.shape).tocsr()\n",
    "    return P_train, P_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_matrix(weight_dict, A):\n",
    "    W = csr_matrix(A.copy())\n",
    "    W.data = np.array([weight_dict.get(rating, 1.0) for rating in A.data])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for hyperparameter tuning\n",
    "import random \n",
    "np.random.seed(42)\n",
    "import itertools\n",
    "import time \n",
    "\n",
    "k_values = [16,24,32,48]\n",
    "lambda_values = [0.001, 0.01, 0.1, 1.0]\n",
    "n_iters_values = [10,20]\n",
    "best_score = -np.inf\n",
    "weights_dicts = [{-1: 1.0, 0: 0.5, 1: 2.0}, \n",
    "                 {-1: 1.0, 0: 1.0, 1: 1.0}, {-1: 1.5, 0: 0.5, 1:1.5} ,\n",
    "                 {-1: 2.0, 0: 0.5, 1: 1.0}]\n",
    "alphas = [1,10,20]\n",
    "best_params = None\n",
    "results = []\n",
    "keep = ratings_per_users[ratings_per_users >= 50].index\n",
    "\n",
    "sample_user_indices = [user_map[u] for u in keep.unique()]\n",
    "\n",
    "# For faster computation during hyperparameter tuning, we can sample a subset of users\n",
    "A_small = A_train.tocsr()[sample_user_indices, :].tocoo()\n",
    "\n",
    "R = A_small.copy()\n",
    "R.data = np.where(R.data > 0, 1.0, 0.0)  # implicit feedback: liked or not\n",
    "grid = random.sample(list(itertools.product(k_values, lambda_values, n_iters_values, alphas)) , 20)\n",
    "\n",
    "# Grid search loop\n",
    "for k, lambda_, n_iters, alpha in grid:\n",
    "    print(f\"\\nEvaluating for k={k}, lambda={lambda_}, n_iters={n_iters}, alpha={alpha}\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    recall = cv_als_implicit(\n",
    "        R,\n",
    "        n_splits=3,\n",
    "        als_params={'k': k, 'lambda': lambda_, 'n_iters': n_iters, 'alpha': alpha}\n",
    "    )\n",
    "\n",
    "    runtime_min = (time.time() - t0) / 60\n",
    "    print(f\"Average Recall@10: {recall:.4f} (took {runtime_min:.2f} min)\")\n",
    "\n",
    "    results.append({'k': k, 'lambda': lambda_, 'n_iters': n_iters, 'alpha': alpha,\n",
    "                    'recall': recall, 'runtime_min': runtime_min})\n",
    "\n",
    "    if recall > best_score:\n",
    "        best_score = recall\n",
    "        best_params = (k, lambda_, n_iters, alpha)\n",
    "\n",
    "print(f\"\\nBest params: k={best_params[0]}, lambda={best_params[1]}, n_iters={best_params[2]}, \"\n",
    "      f\"alpha={best_params[3]} with Recall@10={best_score:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('recall', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confidence_matrix(R, alpha = 20, r_min = 1, r_max = 10, gamma = 1.0):\n",
    "    R_scaled = R.copy().astype(np.float32)\n",
    "    R_scaled.data = np.clip((R_scaled.data - r_min) / (r_max - r_min), 0, 1)\n",
    "    if gamma != 1.0:\n",
    "        R_scaled.data = R_scaled.data ** gamma\n",
    "\n",
    "    C = R_scaled.tocsr()\n",
    "    C.data = 1 + alpha * C.data\n",
    "    return C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating for k=32, lambda=0.01, n_iters=20, alpha=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2981069087982178 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [03:04<00:00,  9.22s/it]\n",
      "100%|██████████| 14502/14502 [00:08<00:00, 1774.77it/s]\n",
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2964751720428467 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [03:03<00:00,  9.15s/it]\n",
      "100%|██████████| 14519/14519 [00:08<00:00, 1734.28it/s]\n",
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.3023688793182373 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [03:05<00:00,  9.26s/it]\n",
      "100%|██████████| 14497/14497 [00:08<00:00, 1796.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAP@10: 0.0009, NDCG@10: 0.0020, Precision@10: 0.0034 (took 10.02 min)\n",
      "\n",
      "Evaluating for k=32, lambda=0.001, n_iters=10, alpha=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.3025798797607422 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [01:31<00:00,  9.13s/it]\n",
      "100%|██████████| 14572/14572 [00:08<00:00, 1713.04it/s]\n",
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.3089771270751953 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [01:32<00:00,  9.22s/it]\n",
      "100%|██████████| 14463/14463 [00:08<00:00, 1784.07it/s]\n",
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.29596590995788574 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [01:36<00:00,  9.66s/it]\n",
      "100%|██████████| 14476/14476 [00:08<00:00, 1734.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAP@10: 0.0006, NDCG@10: 0.0015, Precision@10: 0.0027 (took 5.47 min)\n",
      "\n",
      "Evaluating for k=24, lambda=0.001, n_iters=20, alpha=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2968790531158447 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [03:25<00:00, 10.28s/it]\n",
      "100%|██████████| 14439/14439 [00:09<00:00, 1463.80it/s]\n",
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.30200982093811035 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [03:10<00:00,  9.53s/it]\n",
      "100%|██████████| 14481/14481 [00:07<00:00, 1832.27it/s]\n",
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.3239753246307373 seconds\n",
      "  warnings.warn(\n",
      " 20%|██        | 4/20 [00:49<03:17, 12.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     37\u001b[39m model = AlternatingLeastSquares(factors = k,\n\u001b[32m     38\u001b[39m                                 regularization=lambda_,\n\u001b[32m     39\u001b[39m                                 iterations=n_iters)\n\u001b[32m     40\u001b[39m C = build_confidence_matrix(train, alpha=alpha)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m ranking_k = ranking_metrics_at_k(model, train.T, val.T, K=\u001b[32m10\u001b[39m)\n\u001b[32m     43\u001b[39m map_at_ks.append(ranking_k[\u001b[33m'\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/cpu/als.py:163\u001b[39m, in \u001b[36mAlternatingLeastSquares.fit\u001b[39m\u001b[34m(self, user_items, show_progress, callback)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterations):\n\u001b[32m    162\u001b[39m     s = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCui\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muser_factors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mitem_factors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     solver(\n\u001b[32m    171\u001b[39m         Ciu,\n\u001b[32m    172\u001b[39m         \u001b[38;5;28mself\u001b[39m.item_factors,\n\u001b[32m   (...)\u001b[39m\u001b[32m    175\u001b[39m         num_threads=\u001b[38;5;28mself\u001b[39m.num_threads,\n\u001b[32m    176\u001b[39m     )\n\u001b[32m    177\u001b[39m     progress.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# grid search for hyperparameter tuning\n",
    "from implicit.evaluation import mean_average_precision_at_k, ndcg_at_k , precision_at_k, ranking_metrics_at_k, leave_k_out_split\n",
    "import random \n",
    "np.random.seed(42)\n",
    "import itertools\n",
    "import time \n",
    "\n",
    "k_values = [32,64, 128]\n",
    "lambda_values = [0.0001, 0.01, 1.0]\n",
    "n_iters_values = [20]\n",
    "best_score = -np.inf\n",
    "alphas = [50, 100]\n",
    "gammas = [1.0,2.0]\n",
    "best_params = None\n",
    "results = []\n",
    "keep = ratings_per_users[ratings_per_users >= 10].index\n",
    "\n",
    "sample_user_indices = [user_map[u] for u in keep.unique()]\n",
    "\n",
    "# For faster computation during hyperparameter tuning, we can sample a subset of users\n",
    "R = A_train.tocsr()[sample_user_indices, :].tocoo()\n",
    "\n",
    "#R.data = np.where(R.data > 0, 1.0, 0.0)  # implicit feedback: liked or not\n",
    "grid = random.sample(list(itertools.product(k_values, lambda_values, n_iters_values, alphas)) , 20)\n",
    "\n",
    "results = []\n",
    "# Grid search loop\n",
    "for k, lambda_, n_iters, alpha in grid:\n",
    "    print(f\"\\nEvaluating for k={k}, lambda={lambda_}, n_iters={n_iters}, alpha={alpha}\")\n",
    "    t0 = time.time()\n",
    "    map_at_ks = []\n",
    "    ndcg_ks = []\n",
    "    precision_ks = []\n",
    "    ranking_ks = []\n",
    "    for seed in range(3):\n",
    "        train, val = leave_k_out_split(R, K=1, random_state=42+seed)\n",
    "        model = AlternatingLeastSquares(factors = k,\n",
    "                                        regularization=lambda_,\n",
    "                                        iterations=n_iters)\n",
    "        C = build_confidence_matrix(train, alpha=alpha)\n",
    "        model.fit(C.T)\n",
    "        ranking_k = ranking_metrics_at_k(model, train.T, val.T, K=10)\n",
    "        map_at_ks.append(ranking_k['map'])\n",
    "        ndcg_ks.append(ranking_k['ndcg'])\n",
    "        precision_ks.append(ranking_k['precision'])\n",
    "    \n",
    "    results.append({'k': k, 'lambda': lambda_, 'n_iters': n_iters, 'alpha': alpha, 'map_at_10': np.mean(map_at_ks),\n",
    "                    'ndcg_at_10': np.mean(ndcg_ks), 'precision_at_10': np.mean(precision_ks),\n",
    "                    'runtime_min': (time.time() - t0) / 60})\n",
    "    print(f\"Mean MAP@10: {np.mean(map_at_ks):.4f}, NDCG@10: {np.mean(ndcg_ks):.4f}, Precision@10: {np.mean(precision_ks):.4f} (took {(time.time() - t0) / 60:.2f} min)\")\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('map_at_10', ascending=False)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=128, λ=0.01, iters=25, α=160, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.28827714920043945 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [05:52<00:00, 14.08s/it]\n",
      "100%|██████████| 20577/20577 [00:16<00:00, 1283.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=128, λ=0.03, iters=25, α=160, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.25895190238952637 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [05:45<00:00, 13.82s/it]\n",
      "100%|██████████| 20577/20577 [00:17<00:00, 1199.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=128, λ=0.01, iters=25, α=200, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2386307716369629 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [06:18<00:00, 15.14s/it]\n",
      "100%|██████████| 20577/20577 [00:18<00:00, 1130.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=128, λ=0.01, iters=25, α=160, gamma=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2721128463745117 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [06:10<00:00, 14.83s/it]\n",
      "100%|██████████| 20577/20577 [00:19<00:00, 1080.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=192, λ=0.01, iters=20, α=160, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2093970775604248 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [05:44<00:00, 17.21s/it]\n",
      "100%|██████████| 20577/20577 [00:20<00:00, 996.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=192, λ=0.03, iters=20, α=160, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2700321674346924 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [05:43<00:00, 17.17s/it]\n",
      "100%|██████████| 20577/20577 [00:20<00:00, 993.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=192, λ=0.01, iters=20, α=200, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.21461892127990723 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [05:40<00:00, 17.03s/it]\n",
      "100%|██████████| 20577/20577 [00:20<00:00, 1014.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=256, λ=0.03, iters=20, α=160, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2624948024749756 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [07:40<00:00, 23.02s/it]\n",
      "100%|██████████| 20577/20577 [00:23<00:00, 879.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=256, λ=0.03, iters=20, α=200, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.2097012996673584 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [07:35<00:00, 22.79s/it]\n",
      "100%|██████████| 20577/20577 [00:22<00:00, 900.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=128, λ=0.01, iters=20, α=160, gamma=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.23885083198547363 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [04:41<00:00, 14.06s/it]\n",
      "100%|██████████| 20577/20577 [00:17<00:00, 1145.71it/s]\n"
     ]
    }
   ],
   "source": [
    "k_values = [16,32,64]\n",
    "lambda_values = [0.0001, 0.01, 1.0]\n",
    "n_iters_values = [20]\n",
    "best_score = -np.inf\n",
    "alphas = [50, 100]\n",
    "gammas = [1.0,2.0]\n",
    "\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "\n",
    "# Re-weight implicit feedback\n",
    "\n",
    "train, val = leave_k_out_split(R, K=5, random_state=42+seed)\n",
    "\n",
    "X = bm25_weight(train, K1=1.2, B=0.75)\n",
    "\n",
    "results = []\n",
    "param_grid = [\n",
    "    (128, 0.01, 25, 160, 3.0),\n",
    "    (128, 0.03, 25, 160, 3.0),\n",
    "    (128, 0.01, 25, 200, 3.0),\n",
    "    (128, 0.01, 25, 160, 4.0),\n",
    "    (192, 0.01, 20, 160, 3.0),\n",
    "    (192, 0.03, 20, 160, 3.0),\n",
    "    (192, 0.01, 20, 200, 3.0),\n",
    "    (256, 0.03, 20, 160, 3.0),\n",
    "    (256, 0.03, 20, 200, 3.0),\n",
    "    (128, 0.01, 20, 160, 3.0)  # cg_steps=4\n",
    "]\n",
    "\n",
    "for k, lambda_, n_iters, alpha, gamma in param_grid:\n",
    "    print(f\"Evaluating k={k}, λ={lambda_}, iters={n_iters}, α={alpha}, gamma={gamma}\")\n",
    "    C = build_confidence_matrix(X, alpha=alpha, gamma = gamma)\n",
    "    model = AlternatingLeastSquares(factors=k,\n",
    "                                    regularization=lambda_,\n",
    "                                    iterations=n_iters,\n",
    "                                    random_state=42)\n",
    "    model.fit(C.T)\n",
    "\n",
    "    # Evaluation (user×item)\n",
    "    train_ui = train.T.tocsr().astype(np.float32)\n",
    "    val_ui   = val.T.tocsr().astype(np.float32)\n",
    "    ranking_k = ranking_metrics_at_k(model, train_ui, val_ui, K=10)\n",
    "    results.append((k, lambda_, n_iters, alpha,gamma, ranking_k['precision'], ranking_k['ndcg'], ranking_k['map']))\n",
    "\n",
    "results_df = pd.DataFrame(results, columns = ['k','lambda','n_iters','alpha','gamma','precision@K','NDCG@K','MAP@K']).sort_values('MAP@K', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khallberg/anaconda3/envs/implicit-env/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.28682923316955566 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 25/25 [10:26<00:00, 25.05s/it]\n",
      "100%|██████████| 21036/21036 [00:24<00:00, 869.54it/s]\n"
     ]
    }
   ],
   "source": [
    "best_k, best_lambda, best_n_iters, best_alpha, best_gamma = 256, 0.03, 25, 160, 3.0\n",
    "\n",
    "A_test = coo_matrix((data[test], (rows[test], cols[test])), shape=A.shape)\n",
    "\n",
    "X = bm25_weight(A_train, K1=1.2, B=0.75)\n",
    "\n",
    "C_final = build_confidence_matrix(X, alpha=best_alpha, gamma=best_gamma)\n",
    "model_final = AlternatingLeastSquares(factors=best_k,\n",
    "                                      regularization=best_lambda,\n",
    "                                      iterations=best_n_iters,\n",
    "                                      random_state=42)\n",
    "model_final.fit(C_final.T)\n",
    "U_final_implicit, V_final_implicit = model_final.user_factors, model_final.item_factors\n",
    "\n",
    "#validate on test\n",
    "ranking = ranking_metrics_at_k(model_final, A_train.T.tocsr().astype(np.float32), A_test.T.tocsr().astype(np.float32), K=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.05451895475126513,\n",
       " 'map': 0.02336318942389659,\n",
       " 'ndcg': 0.04980932632808593,\n",
       " 'auc': 0.5202069428600354}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_in_implicit_user(V, liked_items, alpha=5, lambda_=0.03):\n",
    "    \"\"\"\n",
    "    Compute a new user vector given items they've liked (implicit feedback).\n",
    "    \"\"\"\n",
    "    V_i = V[liked_items]\n",
    "    # confidence weights\n",
    "    C_i = 1 + alpha * np.ones(len(liked_items), dtype=np.float32)\n",
    "    \n",
    "    A = V_i.T @ (C_i[:, None] * V_i) + lambda_ * np.eye(V.shape[1])\n",
    "    b = V_i.T @ (C_i * np.ones(len(liked_items), dtype=np.float32))\n",
    "    \n",
    "    u_new = np.linalg.solve(A, b)\n",
    "    return u_new\n",
    "\n",
    "def recommend_new_user(V, liked_items,alpha=5, lambda_=0.03):\n",
    "    u = fold_in_implicit_user(V,liked_items=liked_items, alpha=alpha, lambda_=lambda_)\n",
    "\n",
    "    #calculate scores\n",
    "    scores = V.dot(u)\n",
    "\n",
    "    #normalize between 0 and 1 \n",
    "    scores = (scores - min(scores)) / (max(scores) - min(scores))\n",
    "\n",
    "    return scores \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liked_items = np.array([25, 122, 562])\n",
    "scores = recommend_new_user(V_final_implicit,liked_items)\n",
    "\n",
    "min(scores),max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results[-10:],  columns = ['k','lambda','n_iters','alpha','precision@K','NDCG@K','MAP@K']) \n",
    "\n",
    "results_df_1 = results_df.sort_values('MAP@K', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>lambda</th>\n",
       "      <th>n_iters</th>\n",
       "      <th>alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>precision@K</th>\n",
       "      <th>NDCG@K</th>\n",
       "      <th>MAP@K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.017194</td>\n",
       "      <td>0.007353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.017194</td>\n",
       "      <td>0.007353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.007182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.006903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.006903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>0.006849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>0.006849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>0.006519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>0.006519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>192</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017965</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.006506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>192</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017965</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.006506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>192</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.006248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>192</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.006248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017425</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>0.006067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017425</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>0.006067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.006060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.006060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.005468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.005133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.014629</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.005067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.014629</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>0.005061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.004858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015346</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.004843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>0.004827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.004827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>0.004779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.011635</td>\n",
       "      <td>0.004693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>0.004679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>0.011608</td>\n",
       "      <td>0.004675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>0.004443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.003655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.003238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.002387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  lambda  n_iters  alpha  gamma  precision@K    NDCG@K     MAP@K\n",
       "7  256  0.0300       20    160    3.0     0.019719  0.017194  0.007353\n",
       "7  256  0.0300       20    160    3.0     0.019719  0.017194  0.007353\n",
       "1  128  0.0100       20    100    3.0     0.020077  0.017037  0.007182\n",
       "8  256  0.0300       20    200    3.0     0.018537  0.016263  0.006903\n",
       "8  256  0.0300       20    200    3.0     0.018537  0.016263  0.006903\n",
       "3  128  0.0100       25    160    4.0     0.019101  0.016120  0.006849\n",
       "3  128  0.0100       25    160    4.0     0.019101  0.016120  0.006849\n",
       "4  192  0.0100       20    160    3.0     0.017857  0.015418  0.006519\n",
       "4  192  0.0100       20    160    3.0     0.017857  0.015418  0.006519\n",
       "5  192  0.0300       20    160    3.0     0.017965  0.015407  0.006506\n",
       "5  192  0.0300       20    160    3.0     0.017965  0.015407  0.006506\n",
       "6  192  0.0100       20    200    3.0     0.016745  0.014667  0.006248\n",
       "6  192  0.0100       20    200    3.0     0.016745  0.014667  0.006248\n",
       "9  128  0.0100       20    160    3.0     0.017556  0.014738  0.006129\n",
       "9  128  0.0100       20    160    3.0     0.017556  0.014738  0.006129\n",
       "1  128  0.0300       25    160    3.0     0.017425  0.014679  0.006067\n",
       "1  128  0.0300       25    160    3.0     0.017425  0.014679  0.006067\n",
       "0  128  0.0100       25    160    3.0     0.017402  0.014670  0.006060\n",
       "0  128  0.0100       25    160    3.0     0.017402  0.014670  0.006060\n",
       "2  128  0.0100       25    200    3.0     0.016235  0.013845  0.005786\n",
       "2  128  0.0100       25    200    3.0     0.016235  0.013845  0.005786\n",
       "2  128  0.0100       20    100    2.0     0.017193  0.014187  0.005786\n",
       "3   64  0.0100       20    100    NaN     0.016760  0.013441  0.005468\n",
       "0  128  0.0100       20    100    1.0     0.014727  0.012470  0.005133\n",
       "3  128  0.0100       25    160    2.0     0.014629  0.012379  0.005067\n",
       "5  128  0.0010       20    160    2.0     0.014629  0.012419  0.005061\n",
       "1   64  0.0100       25    160    2.0     0.014891  0.012172  0.004858\n",
       "8   64  0.0001       20     50    NaN     0.015346  0.012075  0.004843\n",
       "4   64  0.0010       20    160    2.0     0.015162  0.012193  0.004827\n",
       "0   64  0.0100       20    160    2.0     0.015115  0.012183  0.004827\n",
       "7  128  0.0100       30    200    2.0     0.013285  0.011479  0.004779\n",
       "2   32  1.0000       20     50    NaN     0.014659  0.011635  0.004693\n",
       "1   32  0.0001       20     50    NaN     0.014651  0.011613  0.004679\n",
       "0   32  0.0100       20     50    NaN     0.014651  0.011608  0.004675\n",
       "6   64  0.0100       30    200    2.0     0.013833  0.011251  0.004443\n",
       "7   32  0.0100       20    100    NaN     0.011724  0.009219  0.003655\n",
       "9   16  1.0000       20     50    NaN     0.009662  0.007864  0.003238\n",
       "4   16  0.0100       20    100    NaN     0.009245  0.007610  0.003095\n",
       "5   64  0.0100       20      1    NaN     0.008148  0.006062  0.002387\n",
       "6   32  0.0100       20      1    NaN     0.006634  0.004975  0.001960"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results =  pd.concat([results_df, all_results]).sort_values('MAP@K', ascending=False)\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/U_final.npy', U_final_implicit)\n",
    "np.save('data/V_final.npy', V_final_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALS\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implicit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
